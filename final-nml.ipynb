{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5048,"databundleVersionId":868335,"sourceType":"competition"},{"sourceId":10262443,"sourceType":"datasetVersion","datasetId":6348530}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Importing required libraries (Dependencies)**","metadata":{}},{"cell_type":"code","source":"import string\nimport re\nimport numpy as np\nfrom numpy import array, argmax, random, take\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import load_model\nfrom keras import optimizers\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:20:24.441440Z","iopub.execute_input":"2024-12-21T16:20:24.441718Z","iopub.status.idle":"2024-12-21T16:20:31.736602Z","shell.execute_reply.started":"2024-12-21T16:20:24.441695Z","shell.execute_reply":"2024-12-21T16:20:31.735953Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## **Defining function to read file and splitting into sentences**","metadata":{}},{"cell_type":"code","source":"def readtext(filename):\n    file = open(filename,mode = 'rt',encoding = 'utf-8')\n    text = file.read()\n    file.close()\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:20:37.222691Z","iopub.execute_input":"2024-12-21T16:20:37.223267Z","iopub.status.idle":"2024-12-21T16:20:37.227371Z","shell.execute_reply.started":"2024-12-21T16:20:37.223237Z","shell.execute_reply":"2024-12-21T16:20:37.226442Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def lines(text):\n    sentence = text.strip().split('\\n')\n    sentence = [i.split('\\t') for i in sentence]\n    return sentence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:20:42.158599Z","iopub.execute_input":"2024-12-21T16:20:42.158936Z","iopub.status.idle":"2024-12-21T16:20:42.163021Z","shell.execute_reply.started":"2024-12-21T16:20:42.158905Z","shell.execute_reply":"2024-12-21T16:20:42.162046Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data = readtext(\"/kaggle/input/french-english/fra.txt\")\nfra_eng = lines(data)\nfra_eng = array(fra_eng)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:20:47.191780Z","iopub.execute_input":"2024-12-21T16:20:47.192090Z","iopub.status.idle":"2024-12-21T16:20:48.993773Z","shell.execute_reply.started":"2024-12-21T16:20:47.192066Z","shell.execute_reply":"2024-12-21T16:20:48.992861Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"type(fra_eng)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:30.252044Z","iopub.execute_input":"2024-12-21T13:12:30.252303Z","iopub.status.idle":"2024-12-21T13:12:30.257770Z","shell.execute_reply.started":"2024-12-21T13:12:30.252281Z","shell.execute_reply":"2024-12-21T13:12:30.256504Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"fra_eng","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:30.259259Z","iopub.execute_input":"2024-12-21T13:12:30.259507Z","iopub.status.idle":"2024-12-21T13:12:30.273978Z","shell.execute_reply.started":"2024-12-21T13:12:30.259486Z","shell.execute_reply":"2024-12-21T13:12:30.273353Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"array([['Go.', 'Va !',\n        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)'],\n       ['Go.', 'Marche.',\n        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)'],\n       ['Go.', 'En route !',\n        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)'],\n       ...,\n       [\"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\",\n        \"Si quelqu'un qui ne connaît pas vos antécédents dit que vous parlez comme un locuteur natif, cela veut dire qu'il a probablement remarqué quelque chose à propos de votre élocution qui lui a fait prendre conscience que vous n'êtes pas un locuteur natif. En d'autres termes, vous ne parlez pas vraiment comme un locuteur natif.\",\n        'CC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #955961 (sacredceltic)'],\n       ['It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning, we might be able to minimize errors.',\n        \"Il est peut-être impossible d'obtenir un Corpus complètement dénué de fautes, étant donnée la nature de ce type d'entreprise collaborative. Cependant, si nous encourageons les membres à produire des phrases dans leurs propres langues plutôt que d'expérimenter dans les langues qu'ils apprennent, nous pourrions être en mesure de réduire les erreurs.\",\n        'CC-BY 2.0 (France) Attribution: tatoeba.org #2024159 (CK) & #2024564 (sacredceltic)'],\n       ['\"I went drinking with one of my boyfriend\\'s friends, and now he\\'s furious at me.\" \"Was this friend a guy or a girl?\" \"A guy, obviously. Why would I go drinking with his female friends?\" \"Yeah, you\\'re right.\" \"His name is Tom. He\\'s really hot, and I really want to go drinking with him again.\"',\n        \"«\\xa0Je suis allée boire avec un ami de mon compagnon, et voilà qu'il est furieux contre moi.\\xa0» «\\xa0Était-ce un gars ou une fille\\xa0?\\xa0» «\\xa0Un gars, bien évidemment. Pourquoi irais-je boire avec ses amies\\xa0?\\xa0» «\\xa0Ouais, ça se comprend.\\xa0» «\\xa0Il s'appelle Tom. Il est trop canon, et j'ai tellement envie d'aller prendre un verre avec lui à nouveau.\\xa0»\",\n        'CC-BY 2.0 (France) Attribution: tatoeba.org #9821215 (DJ_Saidez) & #11726136 (Micsmithel)']],\n      dtype='<U349')"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"**Taking 80,000 datasets for training**","metadata":{}},{"cell_type":"code","source":"fra_eng = fra_eng[:80000,:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:20:56.184220Z","iopub.execute_input":"2024-12-21T16:20:56.184484Z","iopub.status.idle":"2024-12-21T16:20:56.188332Z","shell.execute_reply.started":"2024-12-21T16:20:56.184463Z","shell.execute_reply":"2024-12-21T16:20:56.187466Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#cleaning the data removing puncuations from the data\nfra_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in fra_eng[:,0]]\nfra_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in fra_eng[:,1]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:20:59.404025Z","iopub.execute_input":"2024-12-21T16:20:59.404301Z","iopub.status.idle":"2024-12-21T16:21:00.066988Z","shell.execute_reply.started":"2024-12-21T16:20:59.404278Z","shell.execute_reply":"2024-12-21T16:21:00.066312Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"fra_eng","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:30.996297Z","iopub.execute_input":"2024-12-21T13:12:30.996545Z","iopub.status.idle":"2024-12-21T13:12:31.001502Z","shell.execute_reply.started":"2024-12-21T13:12:30.996523Z","shell.execute_reply":"2024-12-21T13:12:31.000685Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"array([['Go', 'Va ',\n        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)'],\n       ['Go', 'Marche',\n        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)'],\n       ['Go', 'En route ',\n        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)'],\n       ...,\n       ['You did the right thing', 'Vous avez fait ce quil fallait',\n        'CC-BY 2.0 (France) Attribution: tatoeba.org #1663857 (Spamster) & #1673003 (sacredceltic)'],\n       ['You did the right thing', 'Tu as fait ce quil fallait',\n        'CC-BY 2.0 (France) Attribution: tatoeba.org #1663857 (Spamster) & #1673006 (sacredceltic)'],\n       ['You didnt get very far', 'Tu nes pas allé très loin',\n        'CC-BY 2.0 (France) Attribution: tatoeba.org #2283619 (CK) & #2284282 (sacredceltic)']],\n      dtype='<U349')"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"#converting into lower case\nfor i in range(len(fra_eng)):\n    fra_eng[i,0] = fra_eng[i,0].lower()\n    fra_eng[i,1] = fra_eng[i,1].lower()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:31.002342Z","iopub.execute_input":"2024-12-21T13:12:31.002655Z","iopub.status.idle":"2024-12-21T13:12:31.278019Z","shell.execute_reply.started":"2024-12-21T13:12:31.002633Z","shell.execute_reply":"2024-12-21T13:12:31.277435Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"eng_length = []\nfra_length = []\n\nfor i in fra_eng[:,0]:\n    eng_length.append(len(i.split()))\n\nfor i in fra_eng[:,1]:\n    fra_length.append(len(i.split()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:31.280472Z","iopub.execute_input":"2024-12-21T13:12:31.280680Z","iopub.status.idle":"2024-12-21T13:12:31.543958Z","shell.execute_reply.started":"2024-12-21T13:12:31.280663Z","shell.execute_reply":"2024-12-21T13:12:31.543370Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"length_df = pd.DataFrame({'eng':eng_length, 'fra':fra_length})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:31.544914Z","iopub.execute_input":"2024-12-21T13:12:31.545188Z","iopub.status.idle":"2024-12-21T13:12:31.579611Z","shell.execute_reply.started":"2024-12-21T13:12:31.545163Z","shell.execute_reply":"2024-12-21T13:12:31.578844Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"length_df['eng'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:31.580485Z","iopub.execute_input":"2024-12-21T13:12:31.580777Z","iopub.status.idle":"2024-12-21T13:12:31.597775Z","shell.execute_reply.started":"2024-12-21T13:12:31.580748Z","shell.execute_reply":"2024-12-21T13:12:31.597156Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"eng\n4    29984\n3    20438\n5    19726\n2     5989\n6     3616\n1      159\n7       88\nName: count, dtype: int64"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"**Max length of english sequence comes out to be 7**","metadata":{}},{"cell_type":"code","source":"length_df['fra'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:31.598715Z","iopub.execute_input":"2024-12-21T13:12:31.599076Z","iopub.status.idle":"2024-12-21T13:12:31.614954Z","shell.execute_reply.started":"2024-12-21T13:12:31.599039Z","shell.execute_reply":"2024-12-21T13:12:31.614158Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"fra\n4     22881\n5     18120\n3     17202\n6      9893\n2      5729\n7      3511\n1      1240\n8      1071\n9       267\n10       68\n11       16\n12        1\n14        1\nName: count, dtype: int64"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"**Max length of french sequence comes out to be 14**","metadata":{}},{"cell_type":"code","source":"#Tokenization is the process of converting each word in the vocabulary into an integer based on frequency of occurence\n\ndef tokenization(lines):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(lines)\n    return tokenizer\n\neng_tokenizer = tokenization(fra_eng[:, 0])\neng_vocab_size = len(eng_tokenizer.word_index) + 1\n\neng_l = 7\nprint('English Vocabulary Size: %d' % eng_vocab_size)\n\nfra_tokenizer = tokenization(fra_eng[:, 1])\nfra_vocab_size = len(fra_tokenizer.word_index) + 1\n\nfra_l = 14\nprint('French Vocabulary Size: %d' % fra_vocab_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:31.615756Z","iopub.execute_input":"2024-12-21T13:12:31.615970Z","iopub.status.idle":"2024-12-21T13:12:33.192943Z","shell.execute_reply.started":"2024-12-21T13:12:31.615935Z","shell.execute_reply":"2024-12-21T13:12:33.192234Z"}},"outputs":[{"name":"stdout","text":"English Vocabulary Size: 7820\nFrench Vocabulary Size: 18312\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"#converting into sequence and padding them upto maxlen\ndef encode_pad(tokenizer,length,lines):\n    sequence = tokenizer.texts_to_sequences(lines)\n    sequence = pad_sequences(sequence,maxlen = length,padding = 'post')\n    return sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:33.193546Z","iopub.execute_input":"2024-12-21T13:12:33.193745Z","iopub.status.idle":"2024-12-21T13:12:33.197888Z","shell.execute_reply.started":"2024-12-21T13:12:33.193727Z","shell.execute_reply":"2024-12-21T13:12:33.196949Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"#splitting them into training and testing data\nfrom sklearn.model_selection import train_test_split\ntrain,test = train_test_split(fra_eng,test_size = 0.2,random_state = 12)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:33.198830Z","iopub.execute_input":"2024-12-21T13:12:33.199201Z","iopub.status.idle":"2024-12-21T13:12:33.508695Z","shell.execute_reply.started":"2024-12-21T13:12:33.199160Z","shell.execute_reply":"2024-12-21T13:12:33.508019Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"\ntrainX = encode_pad(fra_tokenizer, fra_l, train[:, 1])\ntrainY = encode_pad(eng_tokenizer, eng_l, train[:, 0])\n\ntestX = encode_pad(fra_tokenizer, fra_l, test[:, 1])\ntestY = encode_pad(eng_tokenizer, eng_l, test[:, 0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:33.509495Z","iopub.execute_input":"2024-12-21T13:12:33.509784Z","iopub.status.idle":"2024-12-21T13:12:35.152816Z","shell.execute_reply.started":"2024-12-21T13:12:33.509755Z","shell.execute_reply":"2024-12-21T13:12:35.151726Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"fra_vocab_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:35.153878Z","iopub.execute_input":"2024-12-21T13:12:35.154225Z","iopub.status.idle":"2024-12-21T13:12:35.159264Z","shell.execute_reply.started":"2024-12-21T13:12:35.154189Z","shell.execute_reply":"2024-12-21T13:12:35.158513Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"18312"},"metadata":{}}],"execution_count":42},{"cell_type":"markdown","source":"\n**Now we'll build the Sequential model.The first layer is the embedding layer which projects each token in an N dimensional vector spaceLSTM is the artificial recurrent neural net architecture.It can not only process past data but take feedback from future data as well.**\n\n","metadata":{}},{"cell_type":"code","source":"def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n    model = Sequential()\n    model.add(Embedding(in_vocab, units,  mask_zero=True))\n    model.add(LSTM(units))\n    model.add(RepeatVector(out_timesteps))\n    model.add(LSTM(units, return_sequences=True))\n    model.add(Dense(out_vocab, activation='softmax'))\n    model.build(input_shape=(None, in_timesteps))\n    return model\n\nmodel = build_model(fra_vocab_size, eng_vocab_size, fra_l, eng_l, 512)\nrms = optimizers.RMSprop(learning_rate=0.001)\nmodel.compile(optimizer=rms, loss='sparse_categorical_crossentropy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:35.160056Z","iopub.execute_input":"2024-12-21T13:12:35.160376Z","iopub.status.idle":"2024-12-21T13:12:35.490069Z","shell.execute_reply.started":"2024-12-21T13:12:35.160344Z","shell.execute_reply":"2024-12-21T13:12:35.489166Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:35.490977Z","iopub.execute_input":"2024-12-21T13:12:35.491308Z","iopub.status.idle":"2024-12-21T13:12:35.507179Z","shell.execute_reply.started":"2024-12-21T13:12:35.491277Z","shell.execute_reply":"2024-12-21T13:12:35.506334Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │       \u001b[38;5;34m9,375,744\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m2,099,200\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ repeat_vector_2 (\u001b[38;5;33mRepeatVector\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)              │       \u001b[38;5;34m2,099,200\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7820\u001b[0m)             │       \u001b[38;5;34m4,011,660\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">9,375,744</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ repeat_vector_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7820</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,011,660</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,585,804\u001b[0m (67.08 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,585,804</span> (67.08 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,585,804\u001b[0m (67.08 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,585,804</span> (67.08 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"filename = 'model_best.keras'\ncheckpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n\nhistory = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n          epochs=50, batch_size=512, \n          validation_split = 0.2,\n          callbacks=[checkpoint], verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T14:06:29.112702Z","iopub.execute_input":"2024-12-21T14:06:29.113093Z","iopub.status.idle":"2024-12-21T14:33:14.639321Z","shell.execute_reply.started":"2024-12-21T14:06:29.113056Z","shell.execute_reply":"2024-12-21T14:33:14.638640Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 1.3225\nEpoch 1: val_loss improved from inf to 1.79391, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 341ms/step - loss: 1.3225 - val_loss: 1.7939\nEpoch 2/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 1.2953\nEpoch 2: val_loss improved from 1.79391 to 1.78225, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 320ms/step - loss: 1.2954 - val_loss: 1.7823\nEpoch 3/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - loss: 1.2668\nEpoch 3: val_loss did not improve from 1.78225\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 314ms/step - loss: 1.2669 - val_loss: 1.8374\nEpoch 4/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 1.2531\nEpoch 4: val_loss improved from 1.78225 to 1.75717, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 327ms/step - loss: 1.2531 - val_loss: 1.7572\nEpoch 5/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 1.2334\nEpoch 5: val_loss improved from 1.75717 to 1.74326, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 322ms/step - loss: 1.2335 - val_loss: 1.7433\nEpoch 6/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.2125\nEpoch 6: val_loss improved from 1.74326 to 1.74010, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 325ms/step - loss: 1.2125 - val_loss: 1.7401\nEpoch 7/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.1853\nEpoch 7: val_loss improved from 1.74010 to 1.73459, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - loss: 1.1854 - val_loss: 1.7346\nEpoch 8/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.1683\nEpoch 8: val_loss did not improve from 1.73459\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 318ms/step - loss: 1.1684 - val_loss: 1.7416\nEpoch 9/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.1469\nEpoch 9: val_loss improved from 1.73459 to 1.71181, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - loss: 1.1469 - val_loss: 1.7118\nEpoch 10/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.1301\nEpoch 10: val_loss did not improve from 1.71181\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 317ms/step - loss: 1.1302 - val_loss: 1.7124\nEpoch 11/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.1089\nEpoch 11: val_loss improved from 1.71181 to 1.69778, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - loss: 1.1090 - val_loss: 1.6978\nEpoch 12/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.0908\nEpoch 12: val_loss improved from 1.69778 to 1.68737, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 325ms/step - loss: 1.0909 - val_loss: 1.6874\nEpoch 13/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 1.0694\nEpoch 13: val_loss did not improve from 1.68737\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 317ms/step - loss: 1.0695 - val_loss: 1.6938\nEpoch 14/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.0554\nEpoch 14: val_loss did not improve from 1.68737\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 318ms/step - loss: 1.0554 - val_loss: 1.6893\nEpoch 15/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.0363\nEpoch 15: val_loss did not improve from 1.68737\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 318ms/step - loss: 1.0364 - val_loss: 1.7012\nEpoch 16/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 1.0218\nEpoch 16: val_loss improved from 1.68737 to 1.66966, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - loss: 1.0218 - val_loss: 1.6697\nEpoch 17/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.9961\nEpoch 17: val_loss improved from 1.66966 to 1.65957, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 325ms/step - loss: 0.9962 - val_loss: 1.6596\nEpoch 18/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.9852\nEpoch 18: val_loss did not improve from 1.65957\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 317ms/step - loss: 0.9853 - val_loss: 1.6890\nEpoch 19/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 0.9726\nEpoch 19: val_loss did not improve from 1.65957\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 318ms/step - loss: 0.9726 - val_loss: 1.6596\nEpoch 20/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.9471\nEpoch 20: val_loss improved from 1.65957 to 1.65477, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 324ms/step - loss: 0.9472 - val_loss: 1.6548\nEpoch 21/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 0.9370\nEpoch 21: val_loss improved from 1.65477 to 1.64835, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 323ms/step - loss: 0.9371 - val_loss: 1.6483\nEpoch 22/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 0.9133\nEpoch 22: val_loss improved from 1.64835 to 1.63701, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 323ms/step - loss: 0.9134 - val_loss: 1.6370\nEpoch 23/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.9015\nEpoch 23: val_loss did not improve from 1.63701\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 316ms/step - loss: 0.9016 - val_loss: 1.6426\nEpoch 24/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 0.8932\nEpoch 24: val_loss improved from 1.63701 to 1.63194, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 326ms/step - loss: 0.8932 - val_loss: 1.6319\nEpoch 25/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 0.8707\nEpoch 25: val_loss improved from 1.63194 to 1.62831, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 323ms/step - loss: 0.8708 - val_loss: 1.6283\nEpoch 26/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 0.8499\nEpoch 26: val_loss did not improve from 1.62831\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 315ms/step - loss: 0.8500 - val_loss: 1.6529\nEpoch 27/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.8403\nEpoch 27: val_loss did not improve from 1.62831\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 316ms/step - loss: 0.8403 - val_loss: 1.6350\nEpoch 28/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.8202\nEpoch 28: val_loss improved from 1.62831 to 1.62416, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 325ms/step - loss: 0.8202 - val_loss: 1.6242\nEpoch 29/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.8087\nEpoch 29: val_loss improved from 1.62416 to 1.61809, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 325ms/step - loss: 0.8088 - val_loss: 1.6181\nEpoch 30/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.7933\nEpoch 30: val_loss improved from 1.61809 to 1.61637, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 325ms/step - loss: 0.7934 - val_loss: 1.6164\nEpoch 31/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.7775\nEpoch 31: val_loss improved from 1.61637 to 1.60809, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 325ms/step - loss: 0.7776 - val_loss: 1.6081\nEpoch 32/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.7614\nEpoch 32: val_loss improved from 1.60809 to 1.60614, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 325ms/step - loss: 0.7615 - val_loss: 1.6061\nEpoch 33/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.7538\nEpoch 33: val_loss did not improve from 1.60614\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 317ms/step - loss: 0.7539 - val_loss: 1.6106\nEpoch 34/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.7382\nEpoch 34: val_loss improved from 1.60614 to 1.60519, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 325ms/step - loss: 0.7382 - val_loss: 1.6052\nEpoch 35/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.7260\nEpoch 35: val_loss improved from 1.60519 to 1.60361, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 324ms/step - loss: 0.7260 - val_loss: 1.6036\nEpoch 36/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - loss: 0.7124\nEpoch 36: val_loss did not improve from 1.60361\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 316ms/step - loss: 0.7125 - val_loss: 1.6383\nEpoch 37/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.6982\nEpoch 37: val_loss did not improve from 1.60361\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 317ms/step - loss: 0.6982 - val_loss: 1.6266\nEpoch 38/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.6868\nEpoch 38: val_loss did not improve from 1.60361\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 317ms/step - loss: 0.6869 - val_loss: 1.6091\nEpoch 39/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.6726\nEpoch 39: val_loss did not improve from 1.60361\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 317ms/step - loss: 0.6727 - val_loss: 1.6283\nEpoch 40/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.6591\nEpoch 40: val_loss improved from 1.60361 to 1.60085, saving model to model_best.keras\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 325ms/step - loss: 0.6592 - val_loss: 1.6009\nEpoch 41/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.6477\nEpoch 41: val_loss did not improve from 1.60085\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 317ms/step - loss: 0.6478 - val_loss: 1.6060\nEpoch 42/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.6391\nEpoch 42: val_loss did not improve from 1.60085\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 318ms/step - loss: 0.6392 - val_loss: 1.6019\nEpoch 43/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.6223\nEpoch 43: val_loss did not improve from 1.60085\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 318ms/step - loss: 0.6224 - val_loss: 1.6125\nEpoch 44/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 0.6067\nEpoch 44: val_loss did not improve from 1.60085\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 318ms/step - loss: 0.6069 - val_loss: 1.6098\nEpoch 45/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 0.6003\nEpoch 45: val_loss did not improve from 1.60085\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 318ms/step - loss: 0.6004 - val_loss: 1.6058\nEpoch 46/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 0.5898\nEpoch 46: val_loss did not improve from 1.60085\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 318ms/step - loss: 0.5899 - val_loss: 1.6056\nEpoch 47/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 0.5781\nEpoch 47: val_loss did not improve from 1.60085\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 318ms/step - loss: 0.5781 - val_loss: 1.6122\nEpoch 48/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - loss: 0.5674\nEpoch 48: val_loss did not improve from 1.60085\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 318ms/step - loss: 0.5675 - val_loss: 1.6244\nEpoch 49/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.5643\nEpoch 49: val_loss did not improve from 1.60085\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 317ms/step - loss: 0.5643 - val_loss: 1.6010\nEpoch 50/50\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.5470\nEpoch 50: val_loss did not improve from 1.60085\n\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 316ms/step - loss: 0.5471 - val_loss: 1.6407\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"model = load_model('model_best.keras')\npreds_probabilities = model.predict(testX.reshape((testX.shape[0], testX.shape[1])))\npreds = np.argmax(preds_probabilities, axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T14:34:58.964479Z","iopub.execute_input":"2024-12-21T14:34:58.964790Z","iopub.status.idle":"2024-12-21T14:35:08.784627Z","shell.execute_reply.started":"2024-12-21T14:34:58.964766Z","shell.execute_reply":"2024-12-21T14:35:08.783875Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"def get_word(n, tokenizer):\n    for word, index in tokenizer.word_index.items():\n        if index == n:\n            return word\n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T14:35:11.292097Z","iopub.execute_input":"2024-12-21T14:35:11.292425Z","iopub.status.idle":"2024-12-21T14:35:11.296268Z","shell.execute_reply.started":"2024-12-21T14:35:11.292396Z","shell.execute_reply":"2024-12-21T14:35:11.295537Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"preds_text = []\nfor i in preds:\n    temp = []\n    for j in range(len(i)):\n        t = get_word(i[j], eng_tokenizer)\n        if j > 0: \n            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):  \n                temp.append('')\n            else:\n                temp.append(t)\n             \n        else: \n            if(t == None): \n                temp.append('')\n            else:\n                temp.append(t)            \n        \n    preds_text.append(' '.join(temp))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T14:35:15.361935Z","iopub.execute_input":"2024-12-21T14:35:15.362253Z","iopub.status.idle":"2024-12-21T14:36:11.695393Z","shell.execute_reply.started":"2024-12-21T14:35:15.362227Z","shell.execute_reply":"2024-12-21T14:36:11.694414Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})\npred_df.tail(25)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T14:36:18.843147Z","iopub.execute_input":"2024-12-21T14:36:18.843462Z","iopub.status.idle":"2024-12-21T14:36:18.862933Z","shell.execute_reply.started":"2024-12-21T14:36:18.843436Z","shell.execute_reply":"2024-12-21T14:36:18.862264Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"                        actual                  predicted\n15975      we took a long walk           we did a  walk  \n15976          youre very open        youre very open    \n15977  stop acting like a baby  stop acting like a baby  \n15978             ive got eyes                i am no    \n15979   its all because of you          its all  to you  \n15980          here drink this            heres this     \n15981      my life was a wreck          my life was in   \n15982              im prepared               im free     \n15983      she has few friends     she has few friends   \n15984           i like walnuts        i like watching    \n15985                  get out               get out     \n15986        hows the job hunt        hows was the job   \n15987    we use a lot of water         we make a lot of  \n15988           its all i know        thats all i know   \n15989          we all suffered         we all laughed    \n15990       he loves attention          he wants to be   \n15991            now means now         tell me how now   \n15992        what are we doing       what are we doing   \n15993            youre invited         youre invited     \n15994     how do you like that   what do you think of it \n15995   can you stay for a bit       can you stay a bit  \n15996         do you like fish        do you like fish   \n15997  she made him a new suit      she made him a  joke \n15998         tom looks scared        tom looks tired    \n15999    tom needs urgent help        tom needed help    ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15975</th>\n      <td>we took a long walk</td>\n      <td>we did a  walk</td>\n    </tr>\n    <tr>\n      <th>15976</th>\n      <td>youre very open</td>\n      <td>youre very open</td>\n    </tr>\n    <tr>\n      <th>15977</th>\n      <td>stop acting like a baby</td>\n      <td>stop acting like a baby</td>\n    </tr>\n    <tr>\n      <th>15978</th>\n      <td>ive got eyes</td>\n      <td>i am no</td>\n    </tr>\n    <tr>\n      <th>15979</th>\n      <td>its all because of you</td>\n      <td>its all  to you</td>\n    </tr>\n    <tr>\n      <th>15980</th>\n      <td>here drink this</td>\n      <td>heres this</td>\n    </tr>\n    <tr>\n      <th>15981</th>\n      <td>my life was a wreck</td>\n      <td>my life was in</td>\n    </tr>\n    <tr>\n      <th>15982</th>\n      <td>im prepared</td>\n      <td>im free</td>\n    </tr>\n    <tr>\n      <th>15983</th>\n      <td>she has few friends</td>\n      <td>she has few friends</td>\n    </tr>\n    <tr>\n      <th>15984</th>\n      <td>i like walnuts</td>\n      <td>i like watching</td>\n    </tr>\n    <tr>\n      <th>15985</th>\n      <td>get out</td>\n      <td>get out</td>\n    </tr>\n    <tr>\n      <th>15986</th>\n      <td>hows the job hunt</td>\n      <td>hows was the job</td>\n    </tr>\n    <tr>\n      <th>15987</th>\n      <td>we use a lot of water</td>\n      <td>we make a lot of</td>\n    </tr>\n    <tr>\n      <th>15988</th>\n      <td>its all i know</td>\n      <td>thats all i know</td>\n    </tr>\n    <tr>\n      <th>15989</th>\n      <td>we all suffered</td>\n      <td>we all laughed</td>\n    </tr>\n    <tr>\n      <th>15990</th>\n      <td>he loves attention</td>\n      <td>he wants to be</td>\n    </tr>\n    <tr>\n      <th>15991</th>\n      <td>now means now</td>\n      <td>tell me how now</td>\n    </tr>\n    <tr>\n      <th>15992</th>\n      <td>what are we doing</td>\n      <td>what are we doing</td>\n    </tr>\n    <tr>\n      <th>15993</th>\n      <td>youre invited</td>\n      <td>youre invited</td>\n    </tr>\n    <tr>\n      <th>15994</th>\n      <td>how do you like that</td>\n      <td>what do you think of it</td>\n    </tr>\n    <tr>\n      <th>15995</th>\n      <td>can you stay for a bit</td>\n      <td>can you stay a bit</td>\n    </tr>\n    <tr>\n      <th>15996</th>\n      <td>do you like fish</td>\n      <td>do you like fish</td>\n    </tr>\n    <tr>\n      <th>15997</th>\n      <td>she made him a new suit</td>\n      <td>she made him a  joke</td>\n    </tr>\n    <tr>\n      <th>15998</th>\n      <td>tom looks scared</td>\n      <td>tom looks tired</td>\n    </tr>\n    <tr>\n      <th>15999</th>\n      <td>tom needs urgent help</td>\n      <td>tom needed help</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu\nsumn = 0\nfor i in range(len(pred_df)):\n    reference = pred_df['actual'][0]\n    candidate = pred_df['predicted'][1]\n    score = sentence_bleu([pred_df['actual'][i].split()],pred_df['predicted'][i].split())\n    sumn+=score\n    \nprint(\"The average BLEU score for the translation is {:.2f} %\".format(sumn*100/len(pred_df)))\n# Here we have calculated bleu score for every translation and taken an average","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T14:37:00.093087Z","iopub.execute_input":"2024-12-21T14:37:00.093401Z","iopub.status.idle":"2024-12-21T14:37:01.354092Z","shell.execute_reply.started":"2024-12-21T14:37:00.093377Z","shell.execute_reply":"2024-12-21T14:37:01.353229Z"}},"outputs":[{"name":"stdout","text":"The average BLEU score for the translation is 64.46 %\n","output_type":"stream"}],"execution_count":69}]}